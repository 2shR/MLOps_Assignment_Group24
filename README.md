# MLOps_Assignment_Group24
Group No 24 MLOps Assignment

# End-to-End MLOps Pipeline â€“ California Housing

An end-to-end MLOps pipeline built using the California Housing dataset. This project demonstrates full lifecycle:
- Data preprocessing
- Model training & tracking
- CI/CD deployment
- Docker packaging
- Real-time monitoring & logging
- Model retraining automation

---

## Features

âœ… Data preprocessing  
âœ… Model training (Linear, Tree)  
âœ… Experiment tracking with MLflow  
âœ… Model Registry  
âœ… Flask API with Pydantic validation  
âœ… Dockerized  
âœ… GitHub Actions for CI/CD  
âœ… SQLite logging  
âœ… Prometheus monitoring  
âœ… Retraining on new data  

---

<pre>

mlops-california-housing/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci-cd.yml               # GitHub Actions for CI/CD
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py                     # FastAPI app for serving model predictions
â”‚   â”œâ”€â”€ schemas.py                  # Pydantic models for input validation
â”‚   â”œâ”€â”€ logger.py                   # Logging of requests/responses
â”‚   â”œâ”€â”€ monitor.py                  # Prometheus metrics endpoint
â”‚   â””â”€â”€ retrain.py                  # Retraining logic triggered via endpoint
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ california_housing.csv  # Raw dataset (versioned with DVC if enabled)
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ model.pkl                   # Trained & selected best model
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ eda.ipynb                   # Initial EDA and visualization
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py                    # Training script with MLflow logging
â”‚   â”œâ”€â”€ evaluate.py                 # Evaluate trained models
â”‚   â””â”€â”€ preprocess.py               # Data preprocessing utilities
â”‚
â”œâ”€â”€ Dockerfile                     # Dockerfile for API service
â”œâ”€â”€ docker-compose.yml             # Optional: multi-container setup
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ dvc.yaml                       # DVC pipeline file (if using DVC)
â”œâ”€â”€ .dvc/                          # DVC metadata
â”œâ”€â”€ retrain_trigger.sh             # Script to trigger retraining
â””â”€â”€ README.md                      # Project overview and setup instructions

</pre>
---

## ðŸ”¶ Architecture Overview

The project follows an **end-to-end MLOps pipeline** for the California Housing dataset, covering model development, deployment, and monitoring.

### **1. Data & Model**
- **Dataset**: California Housing dataset.
- **Model Training**: Uses `scikit-learn` for training a regression model.
- **Experiment Tracking**: Managed using **MLflow** with local `mlruns` folder.

### **2. Deployment**
- **API Framework**: Flask-based REST API.
- **Containerization**: Docker used to package the app and model.
- **Port Mapping**: Application exposed at `http://localhost:8081`.

### **3. CI/CD**
- **GitHub Actions**: Automates testing, building, and pushing Docker images to Docker Hub.

### **4. Monitoring**
- **Prometheus**: Collects metrics from the running API.
- **Grafana**: (Optional) For visualizing metrics dashboards.

### **5. Pipeline Workflow**
```mermaid
flowchart TD
    A[Data Source: California Housing] --> B[Data Preprocessing]
    B --> C[Model Training & Hyperparameter Tuning]
    C --> D[MLflow Tracking & Model Registry]
    D --> E[Dockerized Flask API]
    E --> F[Deployment: Local/Docker Hub]

